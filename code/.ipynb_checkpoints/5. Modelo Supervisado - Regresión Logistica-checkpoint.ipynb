{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd567a8f-a01f-4221-9e39-f36dd7e7e884",
   "metadata": {},
   "source": [
    "### Regresión logística para clasificación binaria\n",
    "\n",
    "- La regresión logística se utiliza para problemas de clasificación.\n",
    "- La regresión logística genera probabilidades.\n",
    "\n",
    "#### Reglas probabilísticas:\n",
    "\n",
    "- Si la probabilidad p > 0,5, entonces los datos se etiquetan como 1.\n",
    "- Si la probabilidad p < 0,5, entonces los datos se etiquetan como 0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1bd09bf-7773-4bae-8b53-833035a0a8b8",
   "metadata": {},
   "source": [
    "#### Regresión logística en Scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a511cf1-a108-4edc-9dc4-de5eee72169e",
   "metadata": {},
   "source": [
    "```python\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42)\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d91ca5ce-7952-45c6-bf2a-d5e92676d0ba",
   "metadata": {},
   "source": [
    "#### Predecir probabilidades"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02315f33-70e1-4fcf-b504-2469bbec6a47",
   "metadata": {},
   "source": [
    "```python\n",
    "y_pred_probs = logreg.predict_proba(X_test)[:,1]\n",
    "print(y_pred_probs[0])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39432f17-4cc6-499a-a493-2bb32991bbff",
   "metadata": {},
   "source": [
    "### Umbrales de probabilidad\n",
    "\n",
    "- Por defecto, el umbral de regresión logística es 0,5.\n",
    "- No es específico de la regresión logística.\n",
    "- Los clasificadores KNN también tienen umbrales.\n",
    "\n",
    "¿Qué ocurre si variamos el umbral?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef711291-73e7-4dff-8d3e-ff77a5c0dc60",
   "metadata": {},
   "source": [
    "### Curva ROC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d82bc1-dee8-4a52-9901-419502d3bb58",
   "metadata": {},
   "source": [
    "**ROC (Receiver Operating Characteristic)** es una curva que muestra el rendimiento de un modelo de clasificación binaria al variar el umbral de decisión.\n",
    "\n",
    "- **Eje X:** Tasa de Falsos Positivos (FPR)\n",
    "- **Eje Y:** Tasa de Verdaderos Positivos (TPR o Recall)\n",
    "\n",
    "**¿Para qué sirve?**\n",
    "\n",
    "- Permite visualizar la capacidad del modelo para distinguir entre clases.\n",
    "- Ayuda a comparar distintos modelos de clasificación."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d3189c-4e68-42b6-90e8-0dd7114380a7",
   "metadata": {},
   "source": [
    "```python\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_probs)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Logistic Regression ROC Curve')\n",
    "plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7be5331-2837-4b6f-9ac3-b1f883b0d49f",
   "metadata": {},
   "source": [
    "### ROC AUC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35b9cb4-fd01-471c-afbd-58ad23b51cc6",
   "metadata": {},
   "source": [
    "**AUC (Area Under the Curve)** es una métrica que resume el rendimiento del modelo en una sola cifra entre `0` y `1`.\n",
    "\n",
    "- **AUC = 1.0:** El modelo clasifica perfectamente.\n",
    "- **AUC = 0.5:** El modelo no tiene capacidad predictiva (equivale a lanzar una moneda).\n",
    "\n",
    "**¿Para qué sirve?**\n",
    "\n",
    "- Mide la habilidad del modelo para diferenciar entre clases positivas y negativas.\n",
    "- Es especialmente útil en casos de clases desbalanceadas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6745cb91-26bf-4947-ba5d-b276200219d3",
   "metadata": {},
   "source": [
    "```python\n",
    "from sklearn.metrics import roc_auc_score\n",
    "print(roc_auc_score(y_test, y_pred_probs))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4654b7-c7cb-4499-be75-97e3bd40e1fc",
   "metadata": {},
   "source": [
    "### Ejemplo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def24756-3e24-43a3-9bb0-b25152ff88fe",
   "metadata": {},
   "source": [
    "En la actualidad, la diabetes representa uno de los principales problemas de salud pública a nivel mundial, afectando a millones de personas y generando costos significativos para los sistemas de salud. Una detección temprana y precisa puede marcar la diferencia en el tratamiento y la calidad de vida de los pacientes. Sin embargo, los métodos tradicionales de diagnóstico suelen ser tardíos o requerir procedimientos invasivos y costosos.\n",
    "\n",
    "Frente a este contexto, surge la necesidad de explorar herramientas analíticas que permitan predecir con antelación la presencia de diabetes a partir de variables clínicas y demográficas fácilmente obtenibles. Esto plantea el siguiente interrogante:\n",
    "\n",
    "¿Es posible construir un modelo predictivo, basado en regresión logística, que utilice variables clínicas para estimar con precisión la probabilidad de que un paciente tenga diabetes?\n",
    "\n",
    "Este trabajo utiliza un conjunto de datos clínicos preprocesados y aplica técnicas de escalado y partición de datos, junto con un modelo de regresión logística, para entrenar y evaluar un clasificador. A través de métricas como la probabilidad estimada, la matriz de confusión y el valor del ROC AUC, se busca determinar la capacidad del modelo para asistir en decisiones médicas tempranas con base en la predicción de la condición diabética de los pacientes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1f966549-9d76-446d-9c24-0836c04d6293",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.27060208 0.08157744 0.07884016 0.59335757 0.52139707 0.1228702\n",
      " 0.06507872 0.05328381 0.03461993 0.13238987]\n",
      "   pregnancies  glucose  diastolic  triceps  insulin   bmi    dpf  age  \\\n",
      "0            6      148         72       35        0  33.6  0.627   50   \n",
      "1            1       85         66       29        0  26.6  0.351   31   \n",
      "2            8      183         64        0        0  23.3  0.672   32   \n",
      "3            1       89         66       23       94  28.1  0.167   21   \n",
      "4            0      137         40       35      168  43.1  2.288   33   \n",
      "\n",
      "   diabetes  \n",
      "0         1  \n",
      "1         0  \n",
      "2         1  \n",
      "3         0  \n",
      "4         1  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, classification_report\n",
    "\n",
    "diabetes_df = pd.read_csv(\"../data/diabetes_clean.csv\")\n",
    "X = diabetes_df.drop(\"diabetes\", axis=1).values\n",
    "y = diabetes_df[\"diabetes\"].values\n",
    "\n",
    "\"\"\"\n",
    "Ese mensaje es un ConvergenceWarning, lo lanza scikit-learn cuando el algoritmo de regresión logística no logra converger\n",
    "en el número máximo de iteraciones (max_iter=100 por defecto). Esto significa que el modelo no ha encontrado una solución\n",
    "óptima y probablemente tus resultados no sean confiables aún.\n",
    "\"\"\"\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=21)\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "y_pred_probs = logreg.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(y_pred_probs[:10])\n",
    "print(diabetes_df.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff88449f-b793-4c66-885e-c0ea7d33c5b6",
   "metadata": {},
   "source": [
    "Estas son las probabilidades predichas de que los primeros 10 pacientes del conjunto de prueba tengan diabetes. Valores cercanos a 0 indican baja probabilidad, y valores cercanos a 1 indican alta probabilidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "179ea4e6-1a9d-4706-afe9-a5627a47268a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8123403575989783\n",
      "[[131  13]\n",
      " [ 48  39]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.91      0.81       144\n",
      "           1       0.75      0.45      0.56        87\n",
      "\n",
      "    accuracy                           0.74       231\n",
      "   macro avg       0.74      0.68      0.69       231\n",
      "weighted avg       0.74      0.74      0.72       231\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(roc_auc_score(y_test, y_pred_probs))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da8504f-2d55-4dcf-94ca-a70643be832c",
   "metadata": {},
   "source": [
    "### Interpretación de Metricas\n",
    "#### ROC AUC\n",
    "\n",
    "```\n",
    "ROC AUC = 0.812\n",
    "```\n",
    "\n",
    "**Qué indica:** El modelo tiene buena capacidad discriminativa.\n",
    "\n",
    "**Interpretación:** Hay un 81.2% de probabilidad de que el modelo clasifique correctamente una persona con diabetes frente a una sin diabetes.\n",
    "\n",
    "**Valores aceptables:**\n",
    "- 0.80: Bueno\n",
    "- 0.90: Excelente\n",
    "\n",
    "#### Matriz de Confusión\n",
    "```\n",
    "[[131  13]\n",
    " [ 48  39]]\n",
    "```\n",
    "\n",
    "- Verdaderos negativos (VN): 131\n",
    "- Falsos positivos (FP): 13\n",
    "- Falsos negativos (FN): 48\n",
    "- Verdaderos positivos (VP): 39\n",
    "\n",
    "**Conclusión:** El modelo comete más errores al no detectar personas con diabetes (FN = 48) que al clasificarlas como diabéticas cuando no lo son (`FP = 13`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e4d85d-a31b-4bf9-860c-ab8d0752ec41",
   "metadata": {},
   "source": [
    "### Reporte de Clasificación\n",
    "\n",
    "#### Conclusiones:\n",
    "\n",
    "- El modelo detecta bien a los no diabéticos (91% de recall), pero tiene dificultades con los diabéticos (solo 45% de recall).\n",
    "- Esto sugiere que el modelo es conservador: prefiere evitar falsos positivos, a costa de cometer más falsos negativos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0c41f3-bc22-4eae-8993-b15864a200ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
